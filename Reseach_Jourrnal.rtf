{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1033\deflangfe1033{\fonttbl{\f0\fswiss\fprq2\fcharset0 Calibri;}{\f1\fswiss\fprq2\fcharset161 Calibri Greek;}{\f2\fswiss\fprq2 Calibri;}{\f3\fswiss\fprq2\fcharset161 Calibri;}{\f4\fnil\fcharset2 Symbol;}}
{\*\generator Riched20 10.0.17134}{\*\mmathPr\mdispDef1\mwrapIndent1440 }\viewkind4\uc1 
\pard\nowidctlpar\sa200\sl276\slmult1\f0\fs22\lang9 July 24, 2020\par
10:58 AM - I am working on investigating the effects of varying the parameter Nex in the Wiener filtering functions. The first thing to do will be to add controls for Nex in the functions.\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\nowidctlpar\fi-360\li720\sa200\sl276\slmult1 added Nex as function argument to KSE_modredrun in KSE_moderedrun.jl and adjusted it's call in runme_g3.jl\par
{\pntext\f4\'B7\tab}added it to get_wf in Model_reduction.jl and it's call in KSE_modredrun\par
{\pntext\f4\'B7\tab}Nex is already a parameter of vector_wiener_filter_fft. \par

\pard\nowidctlpar\sa200\sl276\slmult1 Testing work with run on the server. Earlier I tested the "adjusted" scripts which set correlations between district F. modes to zero. \par
11:20 AM - Tested Nex dependent functions.  Test failed because of incomplete coding\par
11:49 AM - Corrected problems and reran test on thelio. This time it worked and the results notebook also started to work though it is going very slowly. \par
12:19 PM - Ran runme_g3_nex.jl script this will run three runs of Nex = 512, 128, 32. It loads the solution each time so It  may be able to be run on my computer. Didn't work becuase I asked for M_out = 1024 when Nex = 512, so I included the code M = min(M_out, Nex) just befor the output h_wf is sent. \par
12:27 PM - Reran runme_g3_nex.jl (job 104). Another problem when running the reduced model it still had M_out > Nex and tried to access h_wf at a index higher than Nex. So, I add the code: M_out > Nex && ( M_out = Nex ) at the beginning.\par
12:35 PM - Reran runme_g3_nex.jl (job 105). Another problem in padding the coefficients for the spectral factorization sicne L > Nex. so I add the code:   \par
l_pad_minus = Nex >= L+1 ? cat(dims = 3,l,zeros(nu,nu,Nex - L - 1)) :  l[:,:,1:Nex] \par
1:11 PM - Reran runme_g3_nex.jl (job 106). Another problem. Time to meet with Dr. Lin so I ran runme_g3.jl at 1:30 PM (108) hope fully I will have results to show. Didn't get results fast enough. But it looks like it went through. \par
1:30 PM - Met with Dr. Lin. He started with a request that I look at how the Wiener filter changes as the obs_gap decreases. So, I said I would have that done by next Wednesday. The thing is that when the obs-gap changes the resultant Wiener filter does a slightly different thing. For instance, when obs_gap is 100 the wiener filter gives you a prediction in 100 steps (whatever the time equivalent of that is). So, that would have to be considered. \par
Next we talked about what I was working on just now, which was adjusting the code, to allow for the z-sepectrum to be computed using fewer evenly spaced grid points on the unit circle. This lead to a discussion on how the z_spectrum was approximated. I need \par
3:23 PM - Ran script runme.jl:\par

\pard\nowidctlpar\li720 using Dates\par
include("Model_KSE.jl")\par
\par
## Parameters for KSE model\par
T = 10^5 # Length (in seconds) of time of run\par
T_disc = Int(T/2) # Length (in seconds) of time discarded\par
P = 21.55  # Period\par
N = 96  # Number of fourier modes used\par
h = 1e-3 # Timestep\par
g = x -> randn()*cos(2\f1\lang1032\'f0*x/P)*(randn() + sin.(2\'f0*x/P))\par
\f0\lang1033 obs_gap = 100\par
\par
uu, vv, tt =  my_KSE_solver(T,\par
    T_disc  = T_disc,\par
    P = P,\par
    N = N,\par
    h = h,\par
    g = g,\par
    n_gap = obs_gap)\par
\par
# set save destinations\par
sol_file = "../data/KSE_Data/KSE_sol_Lin.jld" \par
\par
paramaters = Dict(\par
      "T" => T,\par
      "T_disc" => T_disc,\par
      "P" => P,\par
      "N" => N,\par
      "h" => h,\par
\f1\lang1032       "g" => "x -> cos(\'f0*x/16)*(1 + sin.(\'f0*x/16))",\par
\f0\lang1033       "obs_gap" => obs_gap,\par
      "tm" => now())\par
dat = Dict(\par
     "dat_uu" => uu,\par
     "dat_vv" => vv,\par
     "dat_tt" => tt)\par
Data = merge(paramaters,dat)\par
save(sol_file,Data)\par
\par

\pard\nowidctlpar to produce a run of Dr. Lin's data from the paper (job 109). This didn't work because I forgot to include using JLD\lang9\par

\pard\nowidctlpar\li720\sa200\sl276\slmult1\par

\pard\nowidctlpar\sa200\sl276\slmult1\par
Monday July 27, 2020\par
1:01 PM - Today I got to a late start because Erin and Daniel had doctors appoinments, so me and Emeline watch Tinker Belle. Anyway, what little I have been doing this morning has been reading Chapter 23: Spectral Estimation, from \par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\nowidctlpar\fi-360\li720\sa200\sl276\slmult1 Pollock, David Stephen Geoffrey, Richard C. Green, and Truong Nguyen, eds. \i Handbook of time series analysis, signal processing, and dynamics\i0 . Elsevier, 1999.\par

\pard\nowidctlpar\sa200\sl276\slmult1 It has been going pretty well. The problem here is that it is all done with real times-series. I think I read the chaptr through and try to understand it best I can in this setting and then I'll extend it to complex times-series myself. \par
Actually, I am going to try and take a break from that to get a run of the KSE with Dr. Lin's parameters from\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\nowidctlpar\fi-360\li720\sa200\sl276\slmult1 Lin, Kevin K., and Fei Lu. "Data-driven model reduction, Wiener projections, and the Mori-Zwanzig formalism." arXiv preprint arXiv:1908.07725 (2019).\par
{\pntext\f4\'B7\tab}Lu, Fei, Kevin K. Lin, and Alexandre J. Chorin. "Data-based stochastic model reduction for the Kuramoto\f2\endash Sivashinsky equation." Physica D: Nonlinear Phenomena 340 (2017): 46-57.\f0\par

\pard\nowidctlpar\sa200\sl276\slmult1\par
\lang1033 1:19 - Ran runme.jl (I will rename this one runme_Lin.jl) with the following parameters\par

\pard\nowidctlpar\li720\sl240\slmult1 ## Parameters for KSE model\par
T = 10^5 # Length (in seconds) of time of run\par
T_disc = Int(T/2) # Length (in seconds) of time discarded\par
P = 21.55  # Period\par
N = 96  # Number of fourier modes used\par
h = 1e-3 # Timestep\par
g = x -> randn()*cos(2\f3\lang1032\'f0*x/P)*(randn() + sin.(2\'f0*x/P))\par
obs_gap = 100\f0\lang9\par

\pard\nowidctlpar\sa200\sl276\slmult1\par
This is job 124. The email never came for some reason but the job completed anyway. \par
3:15 PM - I have already downloaded the data made by the a bove job (KSE_sol_Lin.jld) and am now writing the spreadsheet to discuss it. I also read more of chapeter 23, it is interesting. \par
\par
Tuesday, July 28, 2020\par
11:30 AM - Started late. Right now I am coding the smoothers suggested in Pollack (p. 711-12). \par
12:32 - Lunch time.\par
1:18 - Back to work. I am working out the computation of the smoothers useing the polynomials package. Worked on z-spect function pretty much the whole time. \par
5:17 - It looks like using a periodogram with many more points and then smoothing is going to give me a lot better estimates of the z-spectrum. I will continue to pursue this tommorrow. Done for the day. \par
\par
Wednesday, July 29, 2020\par
10:37 AM - Starting research. I will start by reading Pollack on periodograms. \par
12:17 PM - Seeing if I can reprdoduce the periodogram from DSP.jl\par
1:16 PM - I was able to reproduce the periodogram function from DSP.jl. but I don't really know what that does form me at this point. \par
2:00 PM - Meeting with Dr. Lin and group. Use better approximation techniques in code. \par
\par
Thursday, July 30, 2020\par
2:00 PM - A good day so far I did a lot with the new spectral denity estimatorrs and am contemplating how to incorperate them into the code. I wrote a small tutorial/ reference sheet about the DFT and fft. There are two things I want to work on now. (1) use a periodogram analogue, some "cross-periodogram" to approximate the crossspectral density. (2) consider rational approximation of the smoothed spectral density of the predictors and preform the the spetral faztorization on the quotent. \par
4:00 PM - Fininshed writing the function z_crsspect_scalar in Model_reduction.jl it gives much smoother approximations to the cross-spectrum. \par
\par
Friday, July 31, 2020\par
12:00 PM - The goal today will be to use the smoothed periodogram to improve preformance for spectral factiorization. \par
12:54 PM -  I realized if I just increase Nex and L considerable the approximation becaomes a whole lot better. The problem I run into now however is memory. So, I will look into sparse array computation. \par
I put in sparse array computation and it worked out, that is I got a computation without an error. I talked to Dr. Lin for about an hour and a half. I feel a lot like I am finally fitting into the research area. \par
Anyway, I think I will work a little tommorow. I really need to try and work harder each day. \par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\nowidctlpar\fi-360\li720\sa200\sl276\slmult1 Test the new Wiener filter is it stable, how does itn do. \par
{\pntext\f4\'B7\tab}Think about rational approximations!!\par

\pard\nowidctlpar\sa200\sl276\slmult1 Worked: 4 hrs.\par
\par
Monday, August 3, 2020\par
9:41 AM - Today I plan on testing the new and improved filter in many ways. Then I want to read up of rational approximations over the unit circle. \par
To start with I will prepare a script to run this on thelio. \par
11:14 AM - I just set the new code to run. It occured to me to compute the storage it will need. I will do that now. So, I ran a few things and debuged working right on the terminal. The job I just sent was in batch. \par
\b Remeber to sysmetrize autocovariance sequence of nonnegitive lags: Done\par
\b0 I realized that the reason the process was being killed was it that I forgot to change PI ( the control parameter for which factorization method used) was not changed use the SparseArray one. I ahev added SparseArray to both routines now and have kept the "/" routine rather than the pinv. \par
11:30 AM - Met with Stacy she said that I can probably expect funding in the spring, it's just that when I get funding from the graduate college, they only ever approve on a semester by semester basis. \par
2:05 PM - I got the code to run. So Now I will put it on the server and see what comes out. \par
3:36 PM - The server keeps killing the job. It was last run on the server at T = 10^5. Since then I was able to run it on my computer with T = 10^4. I guess I will try to run it on my machine at 10^5 while I am reading and see what happens. If it works then I will have to figure out why it doesn't run so well on the server. Then once I have done that I will need to run an experiment with par = 500, 1000, 1500, 2000 or so. \par
3:41 PM - I now begin a litterature review of rational approximations on the unit circle. \par
5:30 PM - I am done for the day. I thought about the approximation problem. One thing I've got is that it should be a sort of leasts-square things since we have many more points then degrees of freedom in the approximation. \par
10:15 PM - This evening the calculation ran on my computer and here is the output:\par

\pard\nowidctlpar\sl240\slmult1 Sol save location: Data\\KSE_sol_Lin.jld\par
WF save location: Data\\KSE_wf_Lin-Mo10000.jld\par
redmodrun save location: Data\\KSE_rmrun_Lin-Mo10000.jld\par
the Parameters ===================\par
T : 100000\par
P : 21.55\par
short : false\par
h : 0.001\par
gen : _Lin\par
N : 96\par
loadsol : false\par
loadwf : false\par
q : 0.0:0.29156312330299705:27.69849671378472\par
d : 5\par
par : 1500\par
g : x -> cos(\f3\lang1032\'f0*x/16)*(1 + sin.(\'f0*x/16))\par
T_disc : 50000\par
tm : 2020-08-03T15:40:37.076\par
M_out : 10000\par
obs_gap : 100\par
p : 1500\par
n : 3\par
==================================\par
data saved\par
Get_wf computation time: 10387.237116 seconds (27.84 G allocations: 1.112 TiB, 29.33% gc time)\par
Wiener filter saved\par
Reduced Model Run Time:   0.535660 seconds (678.95 k allocations: 170.856 MiB, 8.72% gc time)\par
Reduced Model Run saved\par
\par
\f0\lang9\par

\pard\nowidctlpar\sa200\sl276\slmult1 Tuesday, August 4, 2020\par
9:30 AM - The first thing I did today was run the job that ran on my computer yesterday evening (job 128). It completed just fine on my computer and should have ne reason to die. The results from last night were not good at all so today I will be investigating that. I am glade I have all the files for this on my computer. I will need to really open it up. \par
Everything revolves around three scripts: runme.jl, KSE_modredrun.jl, and Model_reduction.jl.\par
1:31 PM - I really opened it up and took a look. I was analysing the autocovariance sequence of the predictors, and then wanted to inspect the difference between the "true" spectral density and the one approxiated by the Laurent polynomial (the one that is theoretically feed into the factorization function). Then I computed the factorization and multiplied them pointwise to recover the approximated  spectral density. I found that the closeness of the recovered approximation improved as I increased 200 iterations of the CKMS filter to 500, The approximation is still rather poor. When I test N_ckms = 1000, the result was very poor, wosre then all previous this was repeated. I am now trying N_ckms = 500 again. Same as before.\par
While these calculations are happening I am reading Zwanzig I read about the first four pages of CH. 8 and now dicided to read about statistical mechanics fro Chorin\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\nowidctlpar\fi-360\li720\sa200\sl276\slmult1 Chorin, Alexandre Joel, and Ole H. Hald. Stochastic tools in mathematics and science. Vol. 1. New York: Springer, 2009.\par

\pard\nowidctlpar\sa200\sl276\slmult1\par
Wednesday, August 5, 2020\par
12:38 PM - Getting ready for the research meeting. \par
2:14 PM -  Today I am investigating what is going on with the CKMS filter. Currently, I a running it with par = 2000. \par
I am trying to run things on the server using a jupyter note book but it is not going so well. \par
\par
Monday, August 10, 2020\par
The past weekend I have been involved in the Integration Workshop. Which I think went pretty well. It was certainly very interesting. \par
10:47 AM - Today I will continue investigating the wiener filtering code. Ideally I do this with a jupyter notebook on the server. The idea will be to take it noce and slow and be very, very careful. \par
12:40 AM - Just finished meeting with Dr. Lin and get the impression he says too much and listens too little. I feel that the advise given could be improved if the time was taken to understand what I was doing better. At any rate much of what was said are appearently good ideas. \par
Suggestions from meeting:\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\nowidctlpar\fi-360\li720\sa200\sl276\slmult1  Investigate stopping criterion of CKSM factorization algorithm.\par
{\pntext\f4\'B7\tab}Investigate regularization of the Wiener Filter (Maybe do this for tomorrow mornings reading) \par
{\pntext\f4\'B7\tab}Try the new code on a smaller problem. \par

\pard\nowidctlpar\sa200\sl276\slmult1\par
Wednesday, August 12, 2020\par
Today I went back to a linear problem. I have an ODE I am working with. \par
10:37 PM - Created the files "Linear ODE Exploded View.jl\par
\par
Tuesday, August 18, 2020\par
Today I am testing the code on a linear SDE. I have found a few bugs already. \par

\pard 
{\pntext\f0 1.\tab}{\*\pn\pnlvlbody\pnf0\pnindent0\pnstart1\pndec{\pntxta.}}
\nowidctlpar\fi-360\li720\sa200\sl276\slmult1 in `get_wf` when the function `vector_wiener_filter_fft` is called the sig is not adjusted to be temporally offset with the preds. I put in place of `sig` as the argument `signal[1:end-1]`. this way sig[:,i] ~ sum(psi(sig(i-1),..., psi(sig(1)).\par
{\pntext\f0 2.\tab}in `z_crossspect_fft` when the function 'z_crosspect_scalar' is called the arguments given were: `sig[i,1:steps]' and `pred[j,1:steps]` This was done to ensure that the arguments would have the same length. But the function 'z_crosspect_scalar' already handels input of varying length by truncation (exactly what I tried to do in the first place) and since in `z_crossspect_fft` `steps` is possibly bigger then the length `steps=nfft=nextfastfft(steps)` to let do the truncation and padding is better. \par
{\pntext\f0 3.\tab}in `z_crsspect_scalar` I changed the output length from `l` to `nfft` since `nfft` is the standard length when dealing with fft and that is what the function `z_crssspect_fft` wants when it is called.\par

\pard\nowidctlpar\sa200\sl276\slmult1 With these changes, it compiles. \par
\par
Wednesday, August 19, 2020\par
8:40 AM - Yesterday, I saved data and to day I loaded it and analysed it. The data was a reduced model run of length 5e5 - 1e4 run on a Wiener filter computed from a run of length 1e4. The reduced run (no reduction at all actually) blow up at t = 208, it grows exponetially with a facoter of 45.44.\par
Then I began to work on statespace model generator.\par
2:35 AM - Meeting with Dr. Lin it was decided that I would focus on the stability of the factoriztion algorithm. The idea is that we need the to check and make sure the factorization algorithm is converging. So, here is the plan:\par

\pard 
{\pntext\f0 1.\tab}{\*\pn\pnlvlbody\pnf0\pnindent0\pnstart1\pndec{\pntxta.}}
\nowidctlpar\fi-360\li720\sa200\sl276\slmult1 read up on algorithm\par
{\pntext\f0 2.\tab}go back to all the old studies I did and verify the new code. This will require me to clean up my github.\par

\pard\nowidctlpar\sa200\sl276\slmult1\par
Thursday, August 20, 2020\par
9:33 AM - I arrived at the office ready to work at 9:00. Now, I have been relearning git and am preparing to move everything over and organize it.  \par

\pard\nowidctlpar\sa200\sl276\slmult1\par
}
 